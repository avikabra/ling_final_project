{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Homework 5: Using and Finetuning Pretrained Language Models\n",
    "### LING 380/780 Neural Network Models of Linguistic Structure \n",
    "#### Not Due\n",
    "\n",
    "In this last (optional) homework, you will get experience in using and finetuning pretrained language models. \n",
    "\n",
    "\n",
    "### Part 1: Exploring Pretrained Models\n",
    "\n",
    "To begin, wou will need to install the Hugging Face `transformers` library, which provides a simple API for loading and using pretrained models with `pytorch`. You can do this by running the following command at the command line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/babylm_env/lib/python3.11/site-packages (4.46.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/babylm_env/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/anaconda3/envs/babylm_env/lib/python3.11/site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/babylm_env/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/babylm_env/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/babylm_env/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/babylm_env/lib/python3.11/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/babylm_env/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/envs/babylm_env/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/anaconda3/envs/babylm_env/lib/python3.11/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/babylm_env/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/babylm_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/babylm_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/babylm_env/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/babylm_env/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/babylm_env/lib/python3.11/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/babylm_env/lib/python3.11/site-packages (from requests->transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we will import a number of relevant packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import interactive\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will load a pretrained language model. We will begin with the basic `gpt2` model, a decoder-only transformer model that has 124M parameters. (Note that the huggingface also includes larger versions of the [GPT2 model](https://huggingface.co/openai-community/gpt2) as well as many other language models, which you are free to use and explore -- these will be downloaded to your computer when you run this code, so be certain that you have enough disk space for the models you use.)  \n",
    "\n",
    "To begin, we need to load two components: a tokenizer and the model itself. We do this with the following two commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3495e5f2e5c446648449580697450c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c9ff30140444eca987d5bf61f5480d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a857399137428487a7deb0c1a11616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52fb850e8cae404d9b53daa4fac531ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9560eb175e944933a06405047dd08009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/babylm_env/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/anaconda3/envs/babylm_env/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <E03EDA44-89AE-3115-9796-62BA9E0E2EDE> /opt/anaconda3/envs/babylm_env/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <5164AED8-BCBA-3135-84A9-0FCFD7EB4516> /opt/anaconda3/envs/babylm_env/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/opt/anaconda3/envs/babylm_env/lib/python3.11/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/opt/anaconda3/envs/babylm_env/lib/python3.11/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c04d8e67d64370b01bfca8603c1bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ddc3337d8a43acb1bdfeadad8ddfac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'openai-community/gpt2'\n",
    "#model_name = 'facebook/xglm-564M'\n",
    "#model_name = 'ai-forever/mGPT'\n",
    "#model_name = 'meta-llama/Llama-3.2-1B'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokenizer is used to convert text into a format that the model can understand. Specifically, it converts text into a sequence of integers, where each one corresponds to an element in the model's vocabulary. For the models we will be using, the elements of the vocabulary do not necessarily correspond to complete words. While this will be the case for frequent words (where a word is defined as a sequence of characters surrounded by spaces), other words will be broken into subword tokens. Tokens that begin at the beginning of a word are marked with a special character (which is Ġ for GPT-2, and ▁ for other models), so that they are distinguished from a word subpart. The choice of subword tokens is determined by the [Byte Pair Encoding (BPE) algorithm](https://en.wikipedia.org/wiki/Byte_pair_encoding), which begins with a vocabulary of single characters and then iteratively merges the most frequent pairs of characters (as determined by the training data, or a sample thereof) until the vocabulary reaches a desired size. The tokenizer works by greedily finding the longest token in the vocabulary that matches the beginning of the next word in the input. \n",
    "\n",
    "The use of subword tokenization ensures that all input sequences can be turned into sequences of known vocabulary items. Such subword tokenization is particularly useful in the case of languages with rich morphology, since it allows the model to generalize to forms that may not have occurred in the training data. (A single verb in Finnish can have thousands of distinct forms, and having a vocabulary that included all of them would not be feasible.) \n",
    "\n",
    "For GPT-2, the tokenizer we are using includes approximately 50K vocabulary items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by defining a simple sentence, appending a special token to its beginning which indicates the start of the sentence. We then use the tokenizer to convert the sentence into a sequence of integers. (Note that tokenizers for many add the beginning of sentence token themselves, so we will not always need to do this manually.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[50256,   383,  3139,   286,  4486,   318,  1444]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = tokenizer.bos_token + \" \" + \"The capital of Germany is called\"\n",
    "encoded_input = tokenizer(input, return_tensors='pt')\n",
    "\n",
    "encoded_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `encoded_input` is a Python dictionary with two entries: `input_ids` contains the sequence of subword tokens, and `attention_mask` is a binary mask that indicates which tokens are actual input tokens and which are padding tokens. (In this case, we have no padding tokens, so the mask is all 1s.) We can use the `convert_ids_to_tokens` method of the tokenizer to see how the input sequence has been decomposed into subword tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|>', 'ĠThe', 'Ġcapital', 'Ġof', 'ĠGermany', 'Ġis', 'Ġcalled']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(encoded_input['input_ids'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now pass the `encoded_input` to the model to get its output. Since we used the `AutoModelForCausalLM` class to load the model, we are using a model that has been pretrained for language modeling. (The `AutoModel` class includes methods that can be used to load models that have been pretrained for other tasks, including classification or question answering.) The `output` of the model provides a number of objects, including the `loss` (negative log likelihood per word) associated with the input (this is why we provided the `labels` as input) as well as the `logits` associated with each token in the input sequence. `logits` is a tensor of shape `(batch_size, sequence_length, vocab_size)` and each value is the raw output of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**encoded_input, labels=encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you will see, some of the values of these elements (e.g., `hidden_states` and `attentions`) are `None`. If you want the model to return these values, you can set the `output_hidden_states` and `output_attentions` arguments to `True` when you load the model (the values of these arguments will be tuples, one for each layer of the transformer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "                                             return_dict_in_generate=True,      \n",
    "                                             output_attentions=True, \n",
    "                                             output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting aside hidden states and attentions for the moment, we can convert the `logits` into probabilities by applying the `softmax` function (log probabilities can be obtained with the `log_softmax` function). If we take the softmax over the values only at the last position in the sequence, we will get a tensor of shape `(batch_size, vocab_size)` where each value is the predicted probability of the corresponding token in the vocabulary. (Since we are only dealing with a single example in our batch, we can eliminate the batch dimension with the `squeeze` method.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50257])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_word_probs = F.softmax(output.logits[:,-1,:], dim=1).squeeze()\n",
    "\n",
    "last_word_probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use the `argmax` function to find the most likely predicted token, or the `topk` function to find the `k` most likely tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_predicted_probs, top_predicted_words = torch.topk(last_word_probs, 20)\n",
    "top_predicted_words = tokenizer.convert_ids_to_tokens(top_predicted_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot each of these words along with its probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(top_predicted_words, top_predicted_probs.detach().numpy())\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this infrastructure, it is easy to compute the negative log probability (their surprisal) of sentences and use it as a way of measuring the model's knowledge of different aspects of grammar. The `get_log_prob` function defined below takes in a sentence or list of sentences and returns the probability of each (and optionally a graph of the surprisal of each word). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_prob(sentences, graph=True):\n",
    "    if isinstance(sentences,str): \n",
    "        sentences = [sentences]\n",
    "    for i, s in enumerate(sentences):\n",
    "        s_orig = s\n",
    "        if model_name == 'openai-community/gpt2':\n",
    "            s = tokenizer.bos_token + \" \" + s\n",
    "        encoded_input = tokenizer(s, return_tensors='pt')\n",
    "        output = model(**encoded_input, labels=encoded_input[\"input_ids\"])    \n",
    "        logits = output.logits[:,:,:].squeeze()\n",
    "        probs = F.log_softmax(logits,dim=1).detach()\n",
    "        targets = encoded_input['input_ids'][0][1:]\n",
    "        token_list = tokenizer.convert_ids_to_tokens(targets)\n",
    "        token_list = [t[1:] if t.startswith(\"Ġ\") or t.startswith(\"▁\") else \"-\"+t for t in token_list]\n",
    "        log_prob = 0\n",
    "        prob_list = []\n",
    "        for pos, id in enumerate(targets):\n",
    "            prob = probs[pos, id]            \n",
    "            log_prob -= prob\n",
    "            prob_list += [-prob]\n",
    "        if graph:\n",
    "            x = range(len(token_list))\n",
    "            plt.plot(x, prob_list)\n",
    "            for i,j in zip(x, prob_list):\n",
    "                j = j.item()\n",
    "                plt.annotate(token_list[i], xy = (i, j))\n",
    "        print(s_orig)\n",
    "        print(\"NLL:\", float(log_prob))\n",
    "    if graph:\n",
    "        plt.xlabel(\"Position\")\n",
    "        plt.ylabel(\"Surprisal\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following comparison shows that the model has higher surprisal on the sentence with the incorrectly agreeing verb form, and that the higher surprisal occurs at the point of the (incorrect) verb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_log_prob(['The label on the bottles is torn', 'The label on the bottles are torn'], graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intrestingly, though, we see that in the presence of an intervening distractor noun with agreement features that are distinct from those of the subject, the surprisal of the incorrect verb form is increased, suggesting that this (incorrectly) increases the model's acceptability of incorrect agreement:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_log_prob(['The label on the bottle are torn', 'The label on the bottles are torn'], graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As we have discussed, one can also analyze the internal functioning of language models. Above, I pointed out how you can get access to the hidden unit activations and attention weights, by adding arguments when you load the model. There are also a number of packages that have been developed that facilitate this kind of analysis, including [minicons](https://github.com/kanishkamisra/minicons), [diagNNose](https://github.com/i-machine-think/diagNNose) and [captum](https://captum.ai). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have been dealing only with decoder-only models. The `transformers` package also provides access to encoder-only transformers, like BERT, which have been trained to perform masked language modeling. These can be loaded with the `AutoModelForMaskedLM` class.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = AutoModelForMaskedLM.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now carry out masked language modeling with this model by including the `[MASK]` token in the input sentence. By locating the position of the `[MASK]` token in the input sequence, we can find the logits associated with the masked token and extract the probabilities for each possible word at this position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"the capital of [MASK] is called Berlin.\"   \n",
    "encoded_input = bert_tokenizer(input, return_tensors='pt')\n",
    "output = bert_model(**encoded_input)\n",
    "logits = output.logits[:,:,:].squeeze()\n",
    "probs = F.softmax(logits,dim=1).detach()\n",
    "\n",
    "mask_pos = encoded_input['input_ids'][0].tolist().index(bert_tokenizer.mask_token_id)\n",
    "print(mask_pos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look at BERT's guess at the 10 most likely words to fill this slot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_predicted_probs, top_predicted_words = torch.topk(probs[mask_pos], 10)\n",
    "top_predicted_words = bert_tokenizer.convert_ids_to_tokens(top_predicted_words)\n",
    "plt.bar(top_predicted_words, top_predicted_probs.detach().numpy())\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: \n",
    "\n",
    "Using some of the techniques described above, your task is to examine a language model's knowledge of a grammatical phenomenon of your choice. To do that, you will need to construct sets of examples which differ along relevant dimensions, and then examine model behavior on these examples. You should explore surprisal values, either for the entire sentence or for the individual words to determine whether the model is sensitive to the relevant grammatical distinctions. You may also want to look at patterns of attention, or explore the hidden activation vectors by training diagnostic classifiers (or some other method).  \n",
    "\n",
    "You are free to explore a phenomenon we talked about in class or something which we did not discuss. And you can look at phenomenon in English or in some other language. In the latter case, you will need to make use of a language model that has been trained with data from that language. You can either find a model for the specific language of interest or use a multi-lingual model, such as `xglm` or `mGPT`. See the list of models available [here](https://huggingface.co/models?pipeline_tag=text-generation&sort=trending), where you can also filter by languages (using the Languages tab on the top left)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Fine-tuning a Pretrained Model\n",
    "\n",
    "Now, we will explore how you can fine-tune a pretrained model to perform a specific task. We will once again make use of the `transformers` library, this time to fine-tune a pretrained model on the [CoLA dataset](https://nyu-mll.github.io/CoLA/), which consists of sentences annotated for grammaticality. (We are following the example provided [here](https://coe-379l-sp24.readthedocs.io/en/latest/unit04/fine_tuning_transformers.html), so you can refer to that page for more details.)\n",
    "\n",
    "To start off, we will load some useful classes and functions, and set up the device to use for training (so that we can use the GPU if it is available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from evaluate import load\n",
    "import torch\n",
    "import datasets\n",
    "import numpy as np\n",
    "\n",
    "if torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\") \n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load a pretrained model and tokenizer. Here, we will use the `distilbert-base-uncased` model, which is a smaller version of the BERT model. We will load these in a similar way to what we did above, but this time we will use the `AutoModelForSequenceClassification` class, which loads the distilbert model together with an as-yet untrained classifier MLP \"head\"  that takes the model's final hidden states and maps them to logits for two classes (which will correspond to grammatical and ungrammatical sentences). (Note that if you are interested in fine-tuning a model for a different task, you can use a different AutoModel class. See the [documentation](https://huggingface.co/transformers/model_doc/auto.html) for more details.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can examine the structure of the model by printing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next need to load a dataset, using infrastructure provided by the `transformers` package. We will make use of the `glue` dataset available from the `datasets` library, which provides a simple API for loading and working with a number of datasets that have been used to evaluate NLP models. From `glue`, we will load the `cola` dataset.  The `cola` dataset provides a split of the data into training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\"glue\", \"cola\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each item in this dataset includes three components: a string corresponding to the sentence to be evaluated,  a label corresponding to whether the sentence is grammatical (1) or ungrammatical (0), and an index corresponding to the number of the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now tokenize the sentences in the dataset using the tokenizer we loaded above. This will produce a dataset that  includes `input_ids` and `attention_mask` fields for each example. We will also truncate the sentences to a maximum length and use a DataCollator object to pad the sentences to the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sample):\n",
    "    return tokenizer(sample[\"sentence\"], truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess, batched=True)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define a function that specifies how to compute accuracy on the dataset. This function will be used to determine the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load('glue', 'cola')\n",
    "\n",
    "def compute_metrics(preds):\n",
    "    logits, labels = preds\n",
    "    predictions = np.argmax(np.asarray(logits), axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train our model, we use the [Trainer API](https://huggingface.co/docs/transformers/en/main_classes/trainer). This is a high-level API that abstracts away the training loop.  It is designed to be easy to use, but also to be highly customizable. We first specify the traiing arguments, and then use them to create a Trainer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 16 # can experiment with different sizes\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"distilbert-finetuned-cola\", # directory to save the model\n",
    "    eval_strategy = \"epoch\", # evaluate after each epoch\n",
    "    save_strategy = \"epoch\", # save after each epoch\n",
    "    learning_rate=2e-5, # the learning rate to use\n",
    "    per_device_train_batch_size=batch_size, # the batch size\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3, # number of epochs; 5 took about 30 minutes\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "#    use_mps_device=True,\n",
    "    metric_for_best_model=\"matthews_correlation\" # metric associated with COLA GLUE\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,  # the pre-trained model\n",
    "    args,  # the TrainingAgruments, defined above\n",
    "    train_dataset=tokenized_datasets[\"train\"], # the training dataset\n",
    "    eval_dataset=tokenized_datasets[\"validation\"], # the validation dataset\n",
    "    processing_class=tokenizer, # our tokenizer\n",
    "    data_collator=data_collator, # the collator we defined above\n",
    "    compute_metrics=compute_metrics # our function for computing the metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fine-tune the model using the `train` method of the Trainer object. This may take some time, depending on the size of the model, the number of epochs you specify, and the speed of your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we evaluate the model on the validation set to see how well it performs. (Note that we do not use the test set for this because no labels are provided for the test set.) The trainer object itself provides an `evaluate` method that can be used to evaluate the model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CoLA dataset uses the Matthews correlation as its measure of performance. This is a measure of the quality of binary classifications that is particularly useful when the classes are imbalanced. We can however also compute the accuracy of the model on the validation set, by looking at the number of cases on which the model's output matches the true label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "correct = 0\n",
    "for s, l in tqdm(zip(tokenized_datasets['validation']['sentence'], tokenized_datasets['validation']['label'])):\n",
    "    encoded_input = tokenizer(s, return_tensors='pt').to(device)\n",
    "    output = model(**encoded_input)\n",
    "    if torch.argmax(output['logits'], dim=-1) == l:\n",
    "        correct += 1\n",
    "print(f\"Validation accuracy: {(100*correct/len(tokenized_datasets['validation'])):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also test model behavior on a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    encoded_input = tokenizer(sentence, return_tensors='pt').to(device)\n",
    "    output = model(**encoded_input)\n",
    "    return torch.argmax(output['logits'], dim=-1).item()\n",
    "\n",
    "sentences = [\"The boys are happy.\", \"The boys is happy.\", \"The boys in the house are happy.\", \"The boys in the house is happy.\"]\n",
    "for s in sentences:\n",
    "    print(f\"{s} -> {predict(s)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: \n",
    "\n",
    "Experiment with fine-tuning using other models (including other encoder-only models like BERT or RoBERTa, but also decoder-only models like GPT-2) and different tasks/datasets in the GLUE dataset (for example, NLI with the MNLI dataset, sentiment analysis with SST-2, or paraphrase detection with MRPC). You can also experiment with different hyperparameters, including the learning rate, the number of epochs, or the batch size, or look at different ways of converting model output to a response for the task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "babylm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
