# -*- coding: utf-8 -*-
"""fig-gpt-test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10BJl1KF3huJhiQmz57FAmV-FMtQa1nj5
"""

# Exp 1

# >>> print((df['modified_2'].str.split().str.len() - df['modified_1'].str.split().str.len()).mean())
# 0.17

# GPT 2
# 0.55

# Llama
# 0.55

# Exp 2

# >>> print((df['modified_2'].str.split().str.len() - df['modified_1'].str.split().str.len()).mean())
# 0.09714285714285714

# GPT 2
# 0.55

# Llama
# 0.63

import torch
import torch.nn.functional as F
import pandas as pd
from transformers import AutoTokenizer, AutoModelForCausalLM

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

model_name = 'openai-community/gpt2'

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name).to(device)

def get_prob(sentence):

    tokens = tokenizer.encode(sentence)
    tokens_tensor = torch.tensor(tokens).unsqueeze(0).to(device)
    total_log_prob = 0.0

    start_ind = 1

    for i in range(start_ind, len(tokens)):

        input_tokens = tokens[:i]
        target_token = tokens[i]
        input_tensor = torch.tensor(input_tokens).unsqueeze(0).to(device)

        outputs = model(input_tensor)
        logits = outputs.logits

        logits_last = logits[0, -1, :]
        probs = F.softmax(logits_last, dim=-1)
        target_prob = probs[target_token].item()

        total_log_prob += torch.log(torch.tensor(target_prob))

    if not isinstance(total_log_prob, torch.Tensor):
        total_log_prob = torch.tensor(total_log_prob, dtype=torch.float32)

    sentence_probability = torch.exp(total_log_prob).item()

    return sentence_probability

def logprob(sentence):

    tokens = tokenizer.encode(sentence)
    targets = tokens[:]

    input_ids = torch.LongTensZr(tokens).to(device)
    target_ids = torch.LongTensor(targets).to(device)

    with torch.no_grad():
        outputs = model(input_ids, labels=target_ids)
        log_likelihood = outputs[0] * (len(outputs["logits"])-1)

    return log_likelihood

input_path = 'rearranged_dev_filtered.csv'
df = pd.read_csv(input_path, delimiter=',')

def process_row(row):

    sent_1 = row['modified_1'].rstrip('.') + '.'
    sent_2 = row['modified_2'].rstrip('.') + '.'

    prob_1 = get_prob(sent_1)
    prob_2 = get_prob(sent_2)

    result = int((prob_1 < prob_2) == row['labels'])

    # print(sent_1, '|', sent_2, '|', float(prob_1), '|', float(prob_2), '|', result)

    return result

df['result'] = df.apply(process_row, axis=1)

output_path = 'fig-gpt-results.csv'
df.to_csv(output_path, sep=',', index=False)

print(df['result'].mean())